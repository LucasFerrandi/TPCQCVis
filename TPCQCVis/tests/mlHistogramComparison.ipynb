{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4041f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import ROOT\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from TPCQCVis.src.drawHistograms import *\n",
    "from TPCQCVis.src.drawTrending import *\n",
    "from TPCQCVis.src.drawMultiTrending import *\n",
    "from TPCQCVis.src.checkHistograms import *\n",
    "from TPCQCVis.src.checkTrending import *\n",
    "from TPCQCVis.src.drawBetheBloch import *\n",
    "\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "display(HTML(\"<style>table {float:left;}</style>\"))\n",
    "%jsroot on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec0f9d",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Root Files\n",
    "path = \"/cave/alice/data/2022/LHC22m/apass3/\"\n",
    "passName = \"apass3\"\n",
    "fileList = glob.glob(path+\"*_QC.root\")\n",
    "fileList.sort()\n",
    "#fileList = fileList[13:]\n",
    "runList = [fileList[i][36:-8] for i in range(len(fileList))]\n",
    "rootDataFile=[]\n",
    "for file in fileList:\n",
    "    rootDataFile.append(ROOT.TFile.Open(file,\"READ\"))\n",
    "#fileList\n",
    "runList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79aac69",
   "metadata": {},
   "source": [
    "### Show histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c26ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "objectName=\"hdEdxTotMIP_TPC\"\n",
    "[hist,legend,canvas,pad1] = drawHistograms(objectName,rootDataFile,normalize=True,legend=False,log=\"logxyz\",legendNames=runList,pads=False,\n",
    "                                           drawOption=\"L SAME\")\n",
    "canvas.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9157fec",
   "metadata": {},
   "source": [
    "### Run example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8025ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit function to normalize array\n",
    "def normalize(arr, t_min=0, t_max=1):\n",
    "    norm_arr = []\n",
    "    diff = t_max - t_min\n",
    "    diff_arr = max(arr) - min(arr)   \n",
    "    for i in arr:\n",
    "        temp = (((i - min(arr))*diff)/diff_arr) + t_min\n",
    "        norm_arr.append(temp)\n",
    "    return norm_arr\n",
    "\n",
    "# get hists\n",
    "histograms = np.array([np.array(file.PIDQC.Get(\"hdEdxTotMIP_TPC\"))[1:-1] for file in rootDataFile])\n",
    "# repeat for statistics\n",
    "histograms = np.repeat(histograms,1000,axis=0)\n",
    "np.random.shuffle(histograms)\n",
    "# log scaling\n",
    "histograms = np.log(histograms)\n",
    "# normalize\n",
    "histograms = np.array([normalize(hist,0.1,0.9) for hist in histograms])\n",
    "# add noise\n",
    "#histograms = np.array([normalize(hist) for hist in histograms])\n",
    "noise = np.random.randn(*histograms.shape)*1e-2\n",
    "histograms = histograms + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.grid(axis=\"both\")\n",
    "for hist in histograms[0:1000]:\n",
    "    plt.plot(np.array([i for i  in range(len(hist))]),hist,c=\"black\",alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Prepare your histogram data (replace 'histograms' with your actual data)\n",
    "#histograms = np.array([normalize(np.log(np.array(file.PIDQC.Get(\"hdEdxTotMIP_TPC\"))[1:-1])) for file in rootDataFile])\n",
    "#histograms = np.repeat(histograms,1000,axis=0)\n",
    "#np.random.shuffle(histograms)\n",
    "# Define the dimensions of your input and latent space\n",
    "\n",
    "# Define the dimensions of your input and latent space\n",
    "input_dim = histograms.shape[1]\n",
    "print(\"Training with\",len(histograms),\"samples.\")\n",
    "latent_dim = 2\n",
    "\n",
    "# Define the architecture of the autoencoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "dropout_rate = 0.05  # Dropout rate for the dropout layer\n",
    "encoder = Dense(64, activation='relu')(input_layer)\n",
    "encoder = Dropout(dropout_rate)(encoder)\n",
    "encoder = Dense(latent_dim, activation='relu')(encoder)\n",
    "decoder = Dense(64, activation='relu')(encoder)\n",
    "decoder = Dense(input_dim, activation='sigmoid')(decoder)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(histograms, histograms, epochs=30, batch_size=32)\n",
    "\n",
    "# Extract the encoder part of the autoencoder\n",
    "encoder_model = Model(inputs=input_layer, outputs=encoder)\n",
    "\n",
    "# Extract the decoder part of the autoencoder\n",
    "latent_input = Input(shape=(latent_dim,))\n",
    "decoder = autoencoder.layers[-2](latent_input)\n",
    "decoder = autoencoder.layers[-1](decoder)\n",
    "decoder_model = Model(inputs=latent_input, outputs=decoder)\n",
    "\n",
    "# Obtain the reduced representation of your histograms\n",
    "encoded_histograms = encoder_model.predict(histograms)\n",
    "print(\"Encoded Histograms Shape:\", encoded_histograms.shape)\n",
    "\n",
    "# Generate a reconstructed histogram from an arbitrary encoding\n",
    "latent_encoding = np.random.randn(latent_dim)  # Example random latent encoding\n",
    "latent_encoding = latent_encoding.reshape(1, -1)\n",
    "reconstructed_histogram = decoder_model.predict(latent_encoding)\n",
    "\n",
    "# Print the shape of the reconstructed histogram\n",
    "print(\"Reconstructed Histogram Shape:\", reconstructed_histogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get hists\n",
    "histograms = np.array([np.array(file.PIDQC.Get(\"hdEdxTotMIP_TPC\"))[1:-1] for file in rootDataFile])\n",
    "# log scaling\n",
    "histograms = np.log(histograms)\n",
    "# normalize\n",
    "histograms = np.array([normalize(hist,0.1,0.9) for hist in histograms])\n",
    "\n",
    "# Plot the input histogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "for hist in histograms[0:3]:\n",
    "    # Prepare your histogram data (replace 'input_histogram' with your actual data)\n",
    "    input_histogram = hist\n",
    "\n",
    "    # Reshape the input histogram to match the expected input shape of the autoencoder\n",
    "    input_histogram = input_histogram.reshape(1, -1)\n",
    "    # Latent space\n",
    "    encoded_histogram = encoder_model.predict(input_histogram)\n",
    "    print(encoded_histogram)\n",
    "    # Feed the input histogram through the trained autoencoder\n",
    "    reconstructed_histogram = np.mean([autoencoder.predict(input_histogram) for i in range(1)],axis=0)\n",
    "\n",
    "    #plt.plot(range(len(input_histogram[0])), input_histogram[0]-reconstructed_histogram[0])\n",
    "    plt.plot(range(len(input_histogram[0])), input_histogram[0])\n",
    "    #plt.plot(range(len(input_histogram[0])), reconstructed_histogram[0])\n",
    "    #plt.fill_between(range(len(input_histogram[0])), input_histogram[0], reconstructed_histogram[0])\n",
    "    \n",
    "    histogram = decoder_model.predict(encoded_histogram)\n",
    "    plt.plot(range(len(histogram[0])), histogram[0], \"+\")\n",
    "#plt.plot(range(len(reconstructed_histogram[0])), reconstructed_histogram[0])\n",
    "#plt.yscale(\"log\")\n",
    "plt.grid(axis=\"both\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hists\n",
    "histograms = np.array([np.array(file.PIDQC.Get(\"hdEdxTotMIP_TPC\"))[1:-1] for file in rootDataFile])\n",
    "# log scaling\n",
    "histograms = np.log(histograms)\n",
    "# normalize\n",
    "histograms = np.array([normalize(hist,0.1,0.9) for hist in histograms])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "color1 = \"#8A5AC2\"\n",
    "color2 = \"#3575D5\"\n",
    "\n",
    "for i,hist in enumerate(histograms):\n",
    "    input_histogram = hist.reshape(1, -1)\n",
    "    #print(input_histogram.shape)\n",
    "    encoded_histogram = encoder_model.predict(input_histogram)\n",
    "    print(encoded_histogram)\n",
    "    plt.scatter(encoded_histogram[0][0],encoded_histogram[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "color1 = \"#8A5AC2\"\n",
    "color2 = \"#3575D5\"\n",
    "\n",
    "bob = np.linspace(0,10,100)\n",
    "for i,val in enumerate(bob):\n",
    "    histogram = decoder_model.predict(np.array([[0,val]]))\n",
    "    plt.plot(range(len(histogram[0])), histogram[0], c = get_color_gradient(color1, color2, len(bob))[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_RGB(hex_str):\n",
    "    \"\"\" #FFFFFF -> [255,255,255]\"\"\"\n",
    "    #Pass 16 to the integer function for change of base\n",
    "    return [int(hex_str[i:i+2], 16) for i in range(1,6,2)]\n",
    "\n",
    "def get_color_gradient(c1, c2, n):\n",
    "    \"\"\"\n",
    "    Given two hex colors, returns a color gradient\n",
    "    with n colors.\n",
    "    \"\"\"\n",
    "    assert n > 1\n",
    "    c1_rgb = np.array(hex_to_RGB(c1))/255\n",
    "    c2_rgb = np.array(hex_to_RGB(c2))/255\n",
    "    mix_pcts = [x/(n-1) for x in range(n)]\n",
    "    rgb_colors = [((1-mix)*c1_rgb + (mix*c2_rgb)) for mix in mix_pcts]\n",
    "    return [\"#\" + \"\".join([format(int(round(val*255)), \"02x\") for val in item]) for item in rgb_colors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a244afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_histogram[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate random data using make_blobs\n",
    "n_samples = 1000\n",
    "n_features = 50\n",
    "n_clusters = 5\n",
    "X, y = make_blobs(n_samples=n_samples, n_features=n_features, centers=n_clusters, random_state=42)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_result = tsne.fit_transform(X)\n",
    "\n",
    "# Apply UMAP\n",
    "umap_instance = umap.UMAP(n_components=2, random_state=42)\n",
    "umap_result = umap_instance.fit_transform(X)\n",
    "\n",
    "# Plot t-SNE visualization\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=y)\n",
    "plt.title(\"t-SNE Visualization\")\n",
    "\n",
    "# Plot UMAP visualization\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(umap_result[:, 0], umap_result[:, 1], c=y)\n",
    "plt.title(\"UMAP Visualization\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603895be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
